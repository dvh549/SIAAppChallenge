{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, ndcg_score\n",
    "import plotly.express as px\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = pd.read_csv('datasets/recommender/city_codes.csv', encoding=\"latin-1\")\n",
    "cities.loc[cities.destination == \"IAH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [   \n",
    "    ('user_id', 'airport_id', 'airport', 'region', 'season'),\n",
    "    # IF u355541 flew 8 times in the summer\n",
    "        '''\n",
    "        4 to asia    - then asian summer flights get a  4 - 0.2\n",
    "        2 to florida - if florida destination is twice, then +0.2\n",
    "        1 to europe  \n",
    "        1 to latin\n",
    "        '''\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origs = [   \n",
    "    (1, 'ORD', 'Midwest'),\n",
    "    (2, 'LAX', 'West'),\n",
    "    (3, 'SFO', 'West'),\n",
    "    (4, 'IAH', 'South'),\n",
    "    (5, 'DEN', 'Snow'),\n",
    "    (6, 'IAD', 'East'),\n",
    "    (7, 'EWR', 'East')\n",
    "]\n",
    "\n",
    "dests = [\n",
    "    (1, 'ORD', 'Midwest'),\n",
    "    (2, 'LAX', 'Sun'),\n",
    "    (3, 'SFO', 'West'),\n",
    "    (4, 'IAH', 'Sun'),\n",
    "    (5, 'DEN', 'Snow'),\n",
    "    (6, 'IAD', 'East'),\n",
    "    (7, 'EWR', 'East'),\n",
    "    (8, 'MCO', 'Sun'),\n",
    "    (9, 'TPA', 'Sun'),\n",
    "    (10, 'MIA', 'Sun'),\n",
    "    (11, 'RSW', 'Sun'),\n",
    "\n",
    "    # Europe\n",
    "    (12, 'LHR', 'EURO'),\n",
    "    (13, 'CVG', 'EURO'),\n",
    "    (14, 'AMS', 'EURO'),\n",
    "    (15, 'DUB', 'EURO'),\n",
    "    (16, 'BRU', 'EURO'),\n",
    "    (17, 'MUC', 'EURO'),\n",
    "    (18, 'FRA', 'EURO'),\n",
    "    (19, 'BHM', 'EURO'),\n",
    "\n",
    "    # Asia\n",
    "    (20, 'ICN', 'ASIA'),\n",
    "    (21, 'NRT', 'ASIA'),\n",
    "    (22, 'KIX', 'ASIA'),\n",
    "    (23, 'PVG', 'ASIA'),\n",
    "    (24, 'HKG', 'ASIA'),\n",
    "    (25, 'PEK', 'ASIA'),\n",
    "    (26, 'TPE', 'ASIA'),\n",
    "    (27, 'SIN', 'ASIA'),\n",
    "\n",
    "    # Latin America\n",
    "    (28, 'EZE', 'LAT'),\n",
    "    (29, 'GRU', 'LAT'),\n",
    "    (30, 'GIG', 'LAT'),\n",
    "    (31, 'BOG', 'LAT'),\n",
    "    (32, 'SCL', 'LAT'),\n",
    "    (33, 'TGU', 'LAT'),\n",
    "    (34, 'MEX', 'LAT')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame\n",
    "data = pd.DataFrame()\n",
    "\n",
    "# Select amount of random data to generate \n",
    "n = 3000\n",
    "\n",
    "# Append random data to new DataFrame columns\n",
    "data['user_id'] = [random.choice(range(1,99)) for i in range(n)] \n",
    "data['origin_tuple'] = [random.choice(origs) for i in range(n)]\n",
    "data['destination_tuple'] = [random.choice(dests) for i in range(n)]\n",
    "\n",
    "# Transform Tuple() items to DataFrame column\n",
    "data = data.join(pd.DataFrame(data['origin_tuple'].values.tolist(), columns = \n",
    "                              ['orig_id', 'orig', 'orig_reg']\n",
    "                             )\n",
    "                )\n",
    "data = data.join(pd.DataFrame(data['destination_tuple'].values.tolist(), columns = \n",
    "                              ['dest_id', 'dest', 'dest_reg']\n",
    "                             )\n",
    "                )\n",
    "data = data[[\n",
    "    'user_id',\n",
    "    'dest_id',\n",
    "    'orig',\n",
    "    'dest',\n",
    "    'dest_reg'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = data.groupby(['user_id', 'dest_reg'], as_index = False)['dest'].count()\n",
    "counts = counts.rename(columns = {'dest': 'freq'})\n",
    "\n",
    "data = pd.merge(data, counts, on = ['user_id', 'dest_reg'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"datasets/recommender/user_flight_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flight_data = pd.read_csv(\"datasets/recommender/user_flight_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "'''\n",
    "The implicit library expects data as a item-user matrix so we create two matricies,\n",
    "one for fitting the model (item-user) and one for recommendations (user-item)\n",
    "'''\n",
    "sparse_item_user = sparse.csr_matrix((data['freq'].astype(float), (data['dest_id'], data['user_id'])))\n",
    "sparse_user_item = sparse.csr_matrix((data['freq'].astype(float), (data['user_id'], data['dest_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the als model and fit it using the sparse item-user matrix\n",
    "model = implicit.als.AlternatingLeastSquares(factors = 20, regularization = 0.1, iterations = 20)\n",
    "\n",
    "# Calculate the confidence by multiplying it by our alpha value.\n",
    "alpha_val = 15\n",
    "data_conf = (sparse_user_item * alpha_val).astype('double')\n",
    "\n",
    "#Fit the model\n",
    "model.fit(data_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create recommendations for user with id\n",
    "user_id = int(input('Enter User ID: '))\n",
    "\n",
    "# Use the implicit recommender\n",
    "indexes, score = model.recommend(user_id, sparse_user_item[user_id])\n",
    "\n",
    "airports = []\n",
    "scores = []\n",
    "\n",
    "for i in range(len(indexes)):\n",
    "    if not data.dest.loc[data.user_id == indexes[i]].empty:\n",
    "        airports.append(data.dest.loc[data.user_id == indexes[i]].iloc[0])\n",
    "        scores.append(score[i].round(3))\n",
    "\n",
    "# recommendations = pd.DataFrame({\"destination\": airports , \"score\": scores})\n",
    "recommendations = pd.DataFrame({\"destination\": airports})\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.merge(recommendations, cities, on=\"destination\", how=\"left\")\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = pd.read_csv(\"datasets/customer_churn/users.csv\")\n",
    "df_hotel = pd.read_csv(\"datasets/customer_churn/hotels.csv\")\n",
    "df_flight = pd.read_csv(\"datasets/customer_churn/flights.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hotel[\"datetime\"] = pd.to_datetime(df_hotel[\"date\"])\n",
    "df_hotel['monthYear'] = pd.to_datetime(df_hotel['datetime']).dt.to_period('M')\n",
    "df_hotel['year'] = pd.to_datetime(df_hotel['datetime']).dt.year\n",
    "df_hotel['month'] = pd.to_datetime(df_hotel['datetime']).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flight[\"datetime\"] = pd.to_datetime(df_flight[\"date\"])\n",
    "df_flight['monthYear'] = pd.to_datetime(df_flight['datetime']).dt.to_period('M')\n",
    "df_flight['year'] = pd.to_datetime(df_flight['datetime']).dt.year\n",
    "df_flight['month'] = pd.to_datetime(df_flight['datetime']).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flight_combine = df_flight.copy()\n",
    "# Take return ticket's price and date \n",
    "df_flight_combine['price_return'] = (df_flight_combine.groupby(['travelCode','userCode'])['price'].shift(-1))\n",
    "df_flight_combine['date_return'] = (df_flight_combine.groupby(['travelCode','userCode'])['date'].shift(-1))\n",
    "df_flight_combine[\"datetime_return\"] = pd.to_datetime(df_flight_combine[\"date_return\"])\n",
    "# Drop one of the combined columns\n",
    "df_flight_combine = df_flight_combine.dropna(how='any',axis=0)\n",
    "# Calculate travel date\n",
    "df_flight_combine['travel_date'] = df_flight_combine.datetime_return - df_flight_combine.datetime\n",
    "# Extract integer from travel date\n",
    "df_flight_combine['travel_date_int'] = df_flight_combine['travel_date'].astype('str').str.extractall('(\\d+)').unstack().fillna('').sum(axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hotel_join = df_hotel.rename(columns={'name': 'name_hotel', 'days': 'days_hotel', 'total': 'total_hotel'})\n",
    "df_hotel_join = df_hotel_join[['travelCode', 'userCode','name_hotel','days_hotel','total_hotel']]\n",
    "# Left join the round flight and hotel\n",
    "df_flight_hotel = pd.merge(df_flight_combine, df_hotel_join, on=['travelCode', 'userCode'], how='left')\n",
    "# Create bundle column to distinguish the travellers who booked flight and hotel together\n",
    "df_flight_hotel['combo'] = 0\n",
    "df_flight_hotel['combo'] [df_flight_hotel['total_hotel']>0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churned = df_flight_hotel.copy()\n",
    "# If it is the agency's first year order (since 2019/10~2020/09) then label it as old order.\n",
    "conditions = [(df_churned['datetime'] >= '10/01/2019') &  (df_churned['datetime'] <= '09/30/2020')]\n",
    "df_churned['orderOld'] = np.select(conditions, '1', default='0')\n",
    "# If it is the agency's second year order (since 2020/10~2021/09) then label it as new order.\n",
    "conditions = [(df_churned['datetime'] >= '10/01/2020') &  (df_churned['datetime'] <= '09/30/2021')]\n",
    "df_churned['orderNew'] = np.select(conditions, '1', default='0')\n",
    "# Str to Int\n",
    "df_churned['orderNew']=df_churned['orderNew'].astype(int)\n",
    "df_churned['orderOld']=df_churned['orderOld'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the users to calculate how many old orders and new orders if person has each.\n",
    "df_churned_groupby = df_churned.groupby(['userCode']).sum()\n",
    "# Reset the index\n",
    "df_churned_groupby = df_churned_groupby.reset_index()\n",
    "# Add a new column to calculate the old and new orders in total.\n",
    "df_churned_groupby['orderSum'] = df_churned_groupby['orderNew'] + df_churned_groupby['orderOld']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorized customer status into \"new\",\"continued\", \"churned\"\n",
    "df_churned_groupby['userStatus'] = 0\n",
    "df_churned_groupby['userStatus'] [(df_churned_groupby['orderOld'] > 0)&(df_churned_groupby['orderNew'] > 0) ] = 'continued'\n",
    "df_churned_groupby['userStatus'] [(df_churned_groupby['orderOld'] == 0)&(df_churned_groupby['orderNew'] > 0) ] = 'new'\n",
    "df_churned_groupby['userStatus'] [(df_churned_groupby['orderOld'] > 0)&(df_churned_groupby['orderNew'] == 0) ] = 'churned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flight = df_flight.loc[(df_flight['monthYear'] >= '2019-10') & (df_flight['monthYear'] <= '2020-09')]\n",
    "df_hotel = df_hotel.loc[(df_hotel['monthYear'] >= '2019-10') & (df_hotel['monthYear'] <= '2020-09')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 - Combine the round tickets into one.  \n",
    "df_flight_combine = df_flight.copy()\n",
    "# Take return ticket's price and date \n",
    "df_flight_combine['price_return'] = (df_flight_combine.groupby(['travelCode','userCode'])['price'].shift(-1))\n",
    "df_flight_combine['date_return'] = (df_flight_combine.groupby(['travelCode','userCode'])['date'].shift(-1))\n",
    "df_flight_combine[\"datetime_return\"] = pd.to_datetime(df_flight_combine[\"date_return\"])\n",
    "# Drop one of the combined columns\n",
    "df_flight_combine = df_flight_combine.dropna(how='any',axis=0)\n",
    "# Calculate travel date\n",
    "df_flight_combine['travel_date'] = df_flight_combine.datetime_return - df_flight_combine.datetime\n",
    "# Extract integer from travel date\n",
    "df_flight_combine['travel_date_int'] = df_flight_combine['travel_date'].astype('str').str.extractall('(\\d+)').unstack().fillna('').sum(axis=1).astype(int)\n",
    "# Create pseudo column to count \n",
    "df_flight_combine['ticketCount'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hotel_join = df_hotel.rename(columns={'name': 'name_hotel', 'days': 'days_hotel', 'total': 'total_hotel'})\n",
    "df_hotel_join = df_hotel_join[['travelCode', 'userCode','name_hotel','days_hotel','total_hotel']]\n",
    "# Left join the round flight and hotel\n",
    "df_flight_hotel = pd.merge(df_flight_combine, df_hotel_join, on=['travelCode', 'userCode'], how='left')\n",
    "# Create bundle column to distinguish the travller who booked flight and hotel together\n",
    "df_flight_hotel['combo'] = 0\n",
    "df_flight_hotel['combo'] [df_flight_hotel['total_hotel']>0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userCode</th>\n",
       "      <th>travelCode</th>\n",
       "      <th>price</th>\n",
       "      <th>time</th>\n",
       "      <th>distance</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>price_return</th>\n",
       "      <th>travel_date_int</th>\n",
       "      <th>ticketCount</th>\n",
       "      <th>days_hotel</th>\n",
       "      <th>total_hotel</th>\n",
       "      <th>combo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1378</td>\n",
       "      <td>51614.00</td>\n",
       "      <td>72.86</td>\n",
       "      <td>28026.44</td>\n",
       "      <td>105027</td>\n",
       "      <td>334</td>\n",
       "      <td>48116.08</td>\n",
       "      <td>129</td>\n",
       "      <td>52</td>\n",
       "      <td>39.0</td>\n",
       "      <td>9076.28</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>3875.04</td>\n",
       "      <td>6.49</td>\n",
       "      <td>2496.15</td>\n",
       "      <td>10095</td>\n",
       "      <td>50</td>\n",
       "      <td>4183.69</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>386.72</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6318</td>\n",
       "      <td>47779.93</td>\n",
       "      <td>70.81</td>\n",
       "      <td>27242.91</td>\n",
       "      <td>105027</td>\n",
       "      <td>334</td>\n",
       "      <td>45896.92</td>\n",
       "      <td>141</td>\n",
       "      <td>52</td>\n",
       "      <td>42.0</td>\n",
       "      <td>8052.44</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13130</td>\n",
       "      <td>48418.45</td>\n",
       "      <td>67.25</td>\n",
       "      <td>25872.46</td>\n",
       "      <td>105027</td>\n",
       "      <td>334</td>\n",
       "      <td>47954.19</td>\n",
       "      <td>115</td>\n",
       "      <td>52</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8082.12</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>23478</td>\n",
       "      <td>51739.36</td>\n",
       "      <td>72.17</td>\n",
       "      <td>27764.89</td>\n",
       "      <td>105027</td>\n",
       "      <td>334</td>\n",
       "      <td>48018.74</td>\n",
       "      <td>127</td>\n",
       "      <td>52</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6282.96</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>1335</td>\n",
       "      <td>7055750</td>\n",
       "      <td>44052.28</td>\n",
       "      <td>87.41</td>\n",
       "      <td>33655.36</td>\n",
       "      <td>105027</td>\n",
       "      <td>334</td>\n",
       "      <td>60365.39</td>\n",
       "      <td>130</td>\n",
       "      <td>52</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6375.98</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>1336</td>\n",
       "      <td>407583</td>\n",
       "      <td>2326.35</td>\n",
       "      <td>4.53</td>\n",
       "      <td>1741.42</td>\n",
       "      <td>6057</td>\n",
       "      <td>30</td>\n",
       "      <td>3210.53</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>495.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>1337</td>\n",
       "      <td>3940462</td>\n",
       "      <td>26603.98</td>\n",
       "      <td>49.95</td>\n",
       "      <td>19227.59</td>\n",
       "      <td>58567</td>\n",
       "      <td>179</td>\n",
       "      <td>33003.43</td>\n",
       "      <td>73</td>\n",
       "      <td>29</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7303.90</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>1338</td>\n",
       "      <td>815379</td>\n",
       "      <td>5356.01</td>\n",
       "      <td>10.77</td>\n",
       "      <td>4139.76</td>\n",
       "      <td>12114</td>\n",
       "      <td>61</td>\n",
       "      <td>6700.53</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>990.48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>1339</td>\n",
       "      <td>5844646</td>\n",
       "      <td>38082.16</td>\n",
       "      <td>76.20</td>\n",
       "      <td>29326.39</td>\n",
       "      <td>86847</td>\n",
       "      <td>259</td>\n",
       "      <td>49832.44</td>\n",
       "      <td>104</td>\n",
       "      <td>43</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6009.43</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1324 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userCode  travelCode     price   time  distance    year  month  \\\n",
       "0            0        1378  51614.00  72.86  28026.44  105027    334   \n",
       "1            1         460   3875.04   6.49   2496.15   10095     50   \n",
       "2            2        6318  47779.93  70.81  27242.91  105027    334   \n",
       "3            3       13130  48418.45  67.25  25872.46  105027    334   \n",
       "4            4       23478  51739.36  72.17  27764.89  105027    334   \n",
       "...        ...         ...       ...    ...       ...     ...    ...   \n",
       "1319      1335     7055750  44052.28  87.41  33655.36  105027    334   \n",
       "1320      1336      407583   2326.35   4.53   1741.42    6057     30   \n",
       "1321      1337     3940462  26603.98  49.95  19227.59   58567    179   \n",
       "1322      1338      815379   5356.01  10.77   4139.76   12114     61   \n",
       "1323      1339     5844646  38082.16  76.20  29326.39   86847    259   \n",
       "\n",
       "      price_return  travel_date_int  ticketCount  days_hotel  total_hotel  \\\n",
       "0         48116.08              129           52        39.0      9076.28   \n",
       "1          4183.69                5            5         2.0       386.72   \n",
       "2         45896.92              141           52        42.0      8052.44   \n",
       "3         47954.19              115           52        33.0      8082.12   \n",
       "4         48018.74              127           52        30.0      6282.96   \n",
       "...            ...              ...          ...         ...          ...   \n",
       "1319      60365.39              130           52        35.0      6375.98   \n",
       "1320       3210.53                9            3         2.0       495.24   \n",
       "1321      33003.43               73           29        31.0      7303.90   \n",
       "1322       6700.53               19            6         4.0       990.48   \n",
       "1323      49832.44              104           43        29.0      6009.43   \n",
       "\n",
       "      combo  \n",
       "0        16  \n",
       "1         2  \n",
       "2        15  \n",
       "3        15  \n",
       "4        13  \n",
       "...     ...  \n",
       "1319     16  \n",
       "1320      1  \n",
       "1321     11  \n",
       "1322      1  \n",
       "1323     13  \n",
       "\n",
       "[1324 rows x 13 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flight_hotel.groupby('userCode').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_record = df_flight_hotel.groupby('userCode').sum().reset_index()\n",
    "# Take useful record from df_flight_hotel's numerical data\n",
    "df_user_record = df_user_record[['userCode','ticketCount','price','price_return','distance','travel_date_int','days_hotel','total_hotel','combo']]\n",
    "# User list with userStatus (churned or continued) from the previous section \"Transform from Order Dimension to Customer Dimension\n",
    "df_churned_list = df_churned_groupby[['userCode','userStatus']]\n",
    "# Join the above two dataframes\n",
    "df_customer = pd.merge(df_user_record,df_churned_list,on=['userCode'],how='left')\n",
    "# Rename the columns in df_user in case misunderstanding\n",
    "df_user_join = df_user.rename(columns={'code': 'userCode', 'company': 'userCompany', 'name': 'userName'})\n",
    "# Join the above two dataframes\n",
    "df_customer = pd.merge(df_customer,df_user_join,on=['userCode'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer['flightPriceDiffer'] = df_customer['price_return'] - df_customer['price']\n",
    "df_customer['flightPriceSum'] = df_customer['price_return'] + df_customer['price']\n",
    "df_customer['flightPriceDistanceAvg'] = df_customer['flightPriceSum']/df_customer['distance']\n",
    "df_customer['hotelPriceDayAvg'] = df_customer['total_hotel']/df_customer['days_hotel']\n",
    "df_customer['flightPriceDifferDistanceAvg'] = df_customer['flightPriceDiffer']/df_customer['distance']\n",
    "df_customer['flightPriceDifferTicketAvg'] = df_customer['flightPriceDiffer']/df_customer['ticketCount']\n",
    "df_customer['flightPriceTicketAvg'] = df_customer['flightPriceSum']/df_customer['ticketCount']\n",
    "df_customer['comboFrequency'] = df_customer['combo']/df_customer['ticketCount']\n",
    "df_customer['hotelStayDayAvg'] = df_customer['days_hotel']/df_customer['combo']\n",
    "\n",
    "# Unify the form of name\n",
    "df_customer = df_customer.rename(columns={'price': 'flightPriceGo', \n",
    "                                       'price_return': 'flightPriceReturn',\n",
    "                                       'distance': 'flightDistance',\n",
    "                                       'travel_date_int':'travelDays',\n",
    "                                       'days_hotel':'hotelDays',\n",
    "                                        'total_hotel':'hotelPrice'\n",
    "                                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer['userStatus01'] = 0\n",
    "df_customer['userStatus01'] [df_customer['userStatus'] == 'churned'] = 1\n",
    "df_customer['hotelPriceDayAvg'] = df_customer['hotelPriceDayAvg'].fillna(0)\n",
    "df_customer['hotelStayDayAvg'] = df_customer['hotelStayDayAvg'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userCode                        0\n",
       "ticketCount                     0\n",
       "flightPriceGo                   0\n",
       "flightPriceReturn               0\n",
       "flightDistance                  0\n",
       "travelDays                      0\n",
       "hotelDays                       0\n",
       "hotelPrice                      0\n",
       "combo                           0\n",
       "userStatus                      0\n",
       "userCompany                     0\n",
       "userName                        0\n",
       "gender                          0\n",
       "age                             0\n",
       "flightPriceDiffer               0\n",
       "flightPriceSum                  0\n",
       "flightPriceDistanceAvg          0\n",
       "hotelPriceDayAvg                0\n",
       "flightPriceDifferDistanceAvg    0\n",
       "flightPriceDifferTicketAvg      0\n",
       "flightPriceTicketAvg            0\n",
       "comboFrequency                  0\n",
       "hotelStayDayAvg                 0\n",
       "userStatus01                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customer.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [\n",
    "# 'ticketCount',\n",
    "'flightPriceGo',\n",
    "'flightPriceReturn',\n",
    "'flightDistance',\n",
    "'travelDays',\n",
    "'hotelDays',\n",
    "'hotelPrice',\n",
    "'combo',\n",
    "'age',\n",
    "# 'flightPriceSum',\n",
    "# 'flightPriceDistanceAvg',\n",
    "# 'hotelPriceDayAvg',\n",
    "# 'flightPriceDiffer',\n",
    "# 'flightPriceDifferDistanceAvg',\n",
    "# 'flightPriceDifferTicketAvg',\n",
    "# 'flightPriceTicketAvg',\n",
    "'comboFrequency',\n",
    "'hotelStayDayAvg',\n",
    "# 'userCompany'\n",
    "# 'userStatus',\n",
    "# 'userName',\n",
    "# 'gender',\n",
    "# 'ageRange',\n",
    "]\n",
    "outcome = 'userStatus01'\n",
    "X = pd.get_dummies(df_customer[predictors], prefix='', prefix_sep='')\n",
    "y = df_customer[outcome]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state=777)\n",
    "X_res, y_res = rus.fit_resample(X,y)\n",
    "df_X_res = pd.DataFrame(X_res)\n",
    "df_y_res = pd.DataFrame(y_res)\n",
    "df_resample = pd.concat([df_X_res, df_y_res], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    353\n",
       "1    353\n",
       "Name: userStatus01, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imbalance fixed\n",
    "df_resample.userStatus01.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [\n",
    "'ticketCount',\n",
    "'flightPriceGo',\n",
    "'flightPriceReturn',\n",
    "'flightDistance',\n",
    "'travelDays',\n",
    "'hotelDays',\n",
    "'hotelPrice',\n",
    "'combo',\n",
    "'age',\n",
    "# 'flightPriceSum',\n",
    "# 'flightPriceDistanceAvg',\n",
    "# 'hotelPriceDayAvg',\n",
    "# 'flightPriceDiffer',\n",
    "# 'flightPriceDifferDistanceAvg',\n",
    "# 'flightPriceDifferTicketAvg',\n",
    "# 'flightPriceTicketAvg',\n",
    "'comboFrequency',\n",
    "'hotelStayDayAvg',\n",
    "# '4You',\n",
    "# 'Acme Factory',\n",
    "# 'Monsters CYA',\n",
    "# 'Umbrella LTDA',\n",
    "# 'Wonka Company'\n",
    "]\n",
    "outcome = 'userStatus01'\n",
    "X = df_resample[predictors]\n",
    "y = df_resample[outcome]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9858299595141701, 0.9858490566037735)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params ={ 'booster':'gbtree',\n",
    "         'eval_metric': 'auc', #'rmse'\n",
    "         'max_depth': 5,\n",
    "         'min_child_weight':20, \n",
    "         'gamma':0, \n",
    "         'subsample':0.8,\n",
    "         'colsample_bytree':0.8,\n",
    "         'eta':0.01,  \n",
    "         'random_state':7,\n",
    "        }\n",
    "xgb = XGBClassifier(**params)\n",
    "xgb.fit(X_train, y_train)\n",
    "train_accuracy_score = accuracy_score(xgb.predict(X_train), y_train)\n",
    "test_accuracy_score = accuracy_score(xgb.predict(X_test), y_test)\n",
    "train_accuracy_score, test_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticketCount             52.000000\n",
       "flightPriceGo        45139.750000\n",
       "flightPriceReturn    44700.990000\n",
       "flightDistance       22195.940000\n",
       "travelDays             122.000000\n",
       "hotelDays               33.000000\n",
       "hotelPrice            6589.800000\n",
       "combo                   15.000000\n",
       "age                     57.000000\n",
       "comboFrequency           0.288462\n",
       "hotelStayDayAvg          2.200000\n",
       "Name: 103, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticketCount             38.000000\n",
       "flightPriceGo        32576.270000\n",
       "flightPriceReturn    29459.470000\n",
       "flightDistance       16490.200000\n",
       "travelDays              85.000000\n",
       "hotelDays               15.000000\n",
       "hotelPrice            3204.680000\n",
       "combo                    6.000000\n",
       "age                     64.000000\n",
       "comboFrequency           0.157895\n",
       "hotelStayDayAvg          2.500000\n",
       "Name: 544, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = pd.DataFrame({\n",
    "    \"ticketCount\": [X_train.iloc[0].values[0]],\n",
    "    \"flightPriceGo\": [X_train.iloc[0].values[1]],\n",
    "    \"flightPriceReturn\": [X_train.iloc[0].values[2]],\n",
    "    \"flightDistance\": [X_train.iloc[0].values[3]],\n",
    "    \"travelDays\": [X_train.iloc[0].values[4]],\n",
    "    \"hotelDays\": [X_train.iloc[0].values[5]],\n",
    "    \"hotelPrice\": [X_train.iloc[0].values[6]],\n",
    "    \"combo\": [X_train.iloc[0].values[7]],\n",
    "    \"age\": [X_train.iloc[0].values[8]],\n",
    "    \"comboFrequency\": [X_train.iloc[0].values[9]],\n",
    "    \"hotelStayDayAvg\": [X_train.iloc[0].values[10]],\n",
    "}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict2 = pd.DataFrame({\n",
    "    \"ticketCount\": [X_train.iloc[1].values[0]],\n",
    "    \"flightPriceGo\": [X_train.iloc[1].values[1]],\n",
    "    \"flightPriceReturn\": [X_train.iloc[1].values[2]],\n",
    "    \"flightDistance\": [X_train.iloc[1].values[3]],\n",
    "    \"travelDays\": [X_train.iloc[1].values[4]],\n",
    "    \"hotelDays\": [X_train.iloc[1].values[5]],\n",
    "    \"hotelPrice\": [X_train.iloc[1].values[6]],\n",
    "    \"combo\": [X_train.iloc[1].values[7]],\n",
    "    \"age\": [X_train.iloc[1].values[8]],\n",
    "    \"comboFrequency\": [X_train.iloc[1].values[9]],\n",
    "    \"hotelStayDayAvg\": [X_train.iloc[1].values[10]],\n",
    "}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.predict(to_predict2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = pickle.load(open(\"pkl_files/XGBoost_churn.pkl\", \"rb\"))\n",
    "xgb.predict(to_predict2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "\n",
    "import pickle\n",
    "pkl_file = open(\"pkl_files/XGBoost_churn.pkl\", \"wb\")\n",
    "pickle.dump(xgb, pkl_file)\n",
    "pkl_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airbnb Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"datasets/airbnb/train_users_2.csv\")\n",
    "test_df = pd.read_csv(\"datasets/airbnb/test_users.csv\")\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop id column\n",
    "train_df.drop(columns=\"id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [train_df, test_df]:\n",
    "    data.date_account_created = pd.to_datetime(data['date_account_created'])\n",
    "    data['account_year'] = data.date_account_created.dt.year\n",
    "    data['account_month'] = data.date_account_created.dt.month\n",
    "    data['account_day'] = train_df.date_account_created.dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[['timestamp_first_active',\n",
    " 'gender',\n",
    " 'age',\n",
    " 'signup_method',\n",
    " 'signup_flow',\n",
    " 'language',\n",
    " 'affiliate_channel',\n",
    " 'affiliate_provider',\n",
    " 'signup_app',\n",
    " 'first_device_type',\n",
    " 'first_browser',\n",
    " 'account_year',\n",
    " 'account_month',\n",
    " 'account_day','country_destination']]\n",
    "\n",
    "test_df = test_df[['timestamp_first_active',\n",
    " 'gender',\n",
    " 'age',\n",
    " 'signup_method',\n",
    " 'signup_flow',\n",
    " 'language',\n",
    " 'affiliate_channel',\n",
    " 'affiliate_provider',\n",
    " 'signup_app',\n",
    " 'first_device_type',\n",
    " 'first_browser',\n",
    " 'account_year',\n",
    " 'account_month',\n",
    " 'account_day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [train_df,test_df]:\n",
    "    data.age = data.age.apply(lambda x: np.nan if x<18 else x)\n",
    "    data.age = data.age.apply(lambda x: np.nan if x>100 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace nan age values with mean age\n",
    "for data in [train_df,test_df]:\n",
    "    data.age.fillna(data.age.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for any nan values after pre-processing\n",
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, name=\"feature\"):\n",
    "    #Store the 25th and 75th percentile \n",
    "    q25,q75 = np.percentile(df[name],25), np.percentile(df[name],75)\n",
    "    #Calculate the Interquartile range\n",
    "    iqr_cut = 1.5*(q75-q25)\n",
    "    #Create variable of lower and upper cut\n",
    "    lower,upper = q25-iqr_cut, q75+iqr_cut\n",
    "    #Remove the outliers\n",
    "    df = df[(df[name] >= lower) & (df[name] <= upper)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df.copy()\n",
    "train = remove_outliers(train,'age')\n",
    "\n",
    "# Define inputs and target cols\n",
    "inputs_col = train.columns[:-1]\n",
    "target_col = ['country_destination']\n",
    "\n",
    "# Define inputs\n",
    "inputs = train[inputs_col].copy()\n",
    "target = train[target_col].copy()\n",
    "\n",
    "# Define numerical and categorical columns\n",
    "numerical_cols = inputs.select_dtypes(include=['int64','float64']).columns.to_list()\n",
    "categorical_cols = inputs.select_dtypes(include='object').columns.to_list()\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler().fit(inputs[numerical_cols])\n",
    "inputs[numerical_cols] = scaler.transform(inputs[numerical_cols])\n",
    "\n",
    "# label encoding\n",
    "for col in categorical_cols:\n",
    "    # label encoding\n",
    "    encoder = LabelEncoder().fit(inputs[col])\n",
    "    inputs[col] = encoder.transform(inputs[col])\n",
    "    \n",
    "enc_countries = {'NDF':0,'US':1,'FR':2,'CA':3,'GB':4,'ES':5,'IT':6,'PT':7,'NL':8,'DE':9,'AU':10,'other':11}\n",
    "target['country_destination'] = target['country_destination'].apply(lambda x:enc_countries[x])\n",
    "\n",
    "\n",
    "# Define X variable\n",
    "X = inputs[numerical_cols + categorical_cols]\n",
    "# Define y variable\n",
    "y = target['country_destination']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train:', len(X_train))\n",
    "print('y_train:', len(y_train))\n",
    "print('X_val:', len(X_test))\n",
    "print('y_train:', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(random_state=3, n_jobs=-1, max_depth=3, n_estimators=100, objective='multi:softprob', learning_rate=0.3, use_label_encoder=False)\n",
    "xgb.fit(X_train, y_train, eval_metric=\"merror\")\n",
    "train_accuracy_score = accuracy_score(xgb.predict(X_train), y_train)\n",
    "test_accuracy_score = accuracy_score(xgb.predict(X_test), y_test)\n",
    "train_ndcg_score = ndcg_score(pd.get_dummies(y_train).to_numpy(), xgb.predict_proba(X_train))\n",
    "test_ndcg_score = ndcg_score(pd.get_dummies(y_test).to_numpy(), xgb.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_score, test_accuracy_score, train_ndcg_score, test_ndcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_importance_df = pd.DataFrame({'features': X.columns,\n",
    "                  'importance': xgb.feature_importances_}).sort_values('importance',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(xgb_importance_df, x='importance', y='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "\n",
    "import pickle\n",
    "pkl_file = open(\"pkl_files/XGBoost_airbnb.pkl\", \"wb\")\n",
    "pickle.dump(xgb, pkl_file)\n",
    "pkl_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
