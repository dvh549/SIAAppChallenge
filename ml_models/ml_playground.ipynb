{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, ndcg_score\n",
    "import plotly.express as px\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>destination</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3589</th>\n",
       "      <td>Houston</td>\n",
       "      <td>IAH</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         city destination        country\n",
       "3589  Houston         IAH  United States"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities = pd.read_csv('datasets/recommender/city_codes.csv', encoding=\"latin-1\")\n",
    "cities.loc[cities.destination == \"IAH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [   \n",
    "    ('user_id', 'airport_id', 'airport', 'region', 'season'),\n",
    "    # IF u355541 flew 8 times in the summer\n",
    "        '''\n",
    "        4 to asia    - then asian summer flights get a  4 - 0.2\n",
    "        2 to florida - if florida destination is twice, then +0.2\n",
    "        1 to europe  \n",
    "        1 to latin\n",
    "        '''\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "origs = [   \n",
    "    (1, 'ORD', 'Midwest'),\n",
    "    (2, 'LAX', 'West'),\n",
    "    (3, 'SFO', 'West'),\n",
    "    (4, 'IAH', 'South'),\n",
    "    (5, 'DEN', 'Snow'),\n",
    "    (6, 'IAD', 'East'),\n",
    "    (7, 'EWR', 'East')\n",
    "]\n",
    "\n",
    "dests = [\n",
    "    (1, 'ORD', 'Midwest'),\n",
    "    (2, 'LAX', 'Sun'),\n",
    "    (3, 'SFO', 'West'),\n",
    "    (4, 'IAH', 'Sun'),\n",
    "    (5, 'DEN', 'Snow'),\n",
    "    (6, 'IAD', 'East'),\n",
    "    (7, 'EWR', 'East'),\n",
    "    (8, 'MCO', 'Sun'),\n",
    "    (9, 'TPA', 'Sun'),\n",
    "    (10, 'MIA', 'Sun'),\n",
    "    (11, 'RSW', 'Sun'),\n",
    "\n",
    "    # Europe\n",
    "    (12, 'LHR', 'EURO'),\n",
    "    (13, 'CVG', 'EURO'),\n",
    "    (14, 'AMS', 'EURO'),\n",
    "    (15, 'DUB', 'EURO'),\n",
    "    (16, 'BRU', 'EURO'),\n",
    "    (17, 'MUC', 'EURO'),\n",
    "    (18, 'FRA', 'EURO'),\n",
    "    (19, 'BHM', 'EURO'),\n",
    "\n",
    "    # Asia\n",
    "    (20, 'ICN', 'ASIA'),\n",
    "    (21, 'NRT', 'ASIA'),\n",
    "    (22, 'KIX', 'ASIA'),\n",
    "    (23, 'PVG', 'ASIA'),\n",
    "    (24, 'HKG', 'ASIA'),\n",
    "    (25, 'PEK', 'ASIA'),\n",
    "    (26, 'TPE', 'ASIA'),\n",
    "    (27, 'SIN', 'ASIA'),\n",
    "\n",
    "    # Latin America\n",
    "    (28, 'EZE', 'LAT'),\n",
    "    (29, 'GRU', 'LAT'),\n",
    "    (30, 'GIG', 'LAT'),\n",
    "    (31, 'BOG', 'LAT'),\n",
    "    (32, 'SCL', 'LAT'),\n",
    "    (33, 'TGU', 'LAT'),\n",
    "    (34, 'MEX', 'LAT')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame\n",
    "data = pd.DataFrame()\n",
    "\n",
    "# Select amount of random data to generate \n",
    "n = 3000\n",
    "\n",
    "# Append random data to new DataFrame columns\n",
    "data['user_id'] = [random.choice(range(1,99)) for i in range(n)] \n",
    "data['origin_tuple'] = [random.choice(origs) for i in range(n)]\n",
    "data['destination_tuple'] = [random.choice(dests) for i in range(n)]\n",
    "\n",
    "# Transform Tuple() items to DataFrame column\n",
    "data = data.join(pd.DataFrame(data['origin_tuple'].values.tolist(), columns = \n",
    "                              ['orig_id', 'orig', 'orig_reg']\n",
    "                             )\n",
    "                )\n",
    "data = data.join(pd.DataFrame(data['destination_tuple'].values.tolist(), columns = \n",
    "                              ['dest_id', 'dest', 'dest_reg']\n",
    "                             )\n",
    "                )\n",
    "data = data[[\n",
    "    'user_id',\n",
    "    'dest_id',\n",
    "    'orig',\n",
    "    'dest',\n",
    "    'dest_reg'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = data.groupby(['user_id', 'dest_reg'], as_index = False)['dest'].count()\n",
    "counts = counts.rename(columns = {'dest': 'freq'})\n",
    "\n",
    "data = pd.merge(data, counts, on = ['user_id', 'dest_reg'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"datasets/recommender/user_flight_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flight_data = pd.read_csv(\"datasets/recommender/user_flight_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "'''\n",
    "The implicit library expects data as a item-user matrix so we create two matricies,\n",
    "one for fitting the model (item-user) and one for recommendations (user-item)\n",
    "'''\n",
    "sparse_item_user = sparse.csr_matrix((data['freq'].astype(float), (data['dest_id'], data['user_id'])))\n",
    "sparse_user_item = sparse.csr_matrix((data['freq'].astype(float), (data['user_id'], data['dest_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 1538.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the als model and fit it using the sparse item-user matrix\n",
    "model = implicit.als.AlternatingLeastSquares(factors = 20, regularization = 0.1, iterations = 20)\n",
    "\n",
    "# Calculate the confidence by multiplying it by our alpha value.\n",
    "alpha_val = 15\n",
    "data_conf = (sparse_user_item * alpha_val).astype('double')\n",
    "\n",
    "#Fit the model\n",
    "model.fit(data_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IAH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LHR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HKG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BRU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BRU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DUB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  destination\n",
       "0         TPA\n",
       "1         IAH\n",
       "2         GIG\n",
       "3         LHR\n",
       "4         HKG\n",
       "5         MIA\n",
       "6         BRU\n",
       "7         IAD\n",
       "8         BRU\n",
       "9         DUB"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create recommendations for user with id\n",
    "user_id = int(input('Enter User ID: '))\n",
    "\n",
    "# Use the implicit recommender\n",
    "indexes, score = model.recommend(user_id, sparse_user_item[user_id])\n",
    "\n",
    "airports = []\n",
    "scores = []\n",
    "\n",
    "for i in range(len(indexes)):\n",
    "    if not data.dest.loc[data.user_id == indexes[i]].empty:\n",
    "        airports.append(data.dest.loc[data.user_id == indexes[i]].iloc[0])\n",
    "        scores.append(score[i].round(3))\n",
    "\n",
    "# recommendations = pd.DataFrame({\"destination\": airports , \"score\": scores})\n",
    "recommendations = pd.DataFrame({\"destination\": airports})\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destination</th>\n",
       "      <th>score</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TPA</td>\n",
       "      <td>1.023</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IAH</td>\n",
       "      <td>0.932</td>\n",
       "      <td>Houston</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GIG</td>\n",
       "      <td>0.877</td>\n",
       "      <td>Rio De Janeiro</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LHR</td>\n",
       "      <td>0.819</td>\n",
       "      <td>London</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HKG</td>\n",
       "      <td>0.773</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MIA</td>\n",
       "      <td>0.711</td>\n",
       "      <td>Miami</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BRU</td>\n",
       "      <td>0.685</td>\n",
       "      <td>Brussels</td>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IAD</td>\n",
       "      <td>0.580</td>\n",
       "      <td>Dulles, DC</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BRU</td>\n",
       "      <td>0.540</td>\n",
       "      <td>Brussels</td>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DUB</td>\n",
       "      <td>0.510</td>\n",
       "      <td>Dublin</td>\n",
       "      <td>Ireland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  destination  score            city         country\n",
       "0         TPA  1.023           Tampa   United States\n",
       "1         IAH  0.932         Houston   United States\n",
       "2         GIG  0.877  Rio De Janeiro          Brazil\n",
       "3         LHR  0.819          London  United Kingdom\n",
       "4         HKG  0.773       Hong Kong           China\n",
       "5         MIA  0.711           Miami   United States\n",
       "6         BRU  0.685        Brussels         Belgium\n",
       "7         IAD  0.580      Dulles, DC   United States\n",
       "8         BRU  0.540        Brussels         Belgium\n",
       "9         DUB  0.510          Dublin         Ireland"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = pd.merge(recommendations, cities, on=\"destination\", how=\"left\")\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airbnb Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"datasets/airbnb/train_users_2.csv\")\n",
    "test_df = pd.read_csv(\"datasets/airbnb/test_users.csv\")\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop id column\n",
    "train_df.drop(columns=\"id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [train_df, test_df]:\n",
    "    data.date_account_created = pd.to_datetime(data['date_account_created'])\n",
    "    data['account_year'] = data.date_account_created.dt.year\n",
    "    data['account_month'] = data.date_account_created.dt.month\n",
    "    data['account_day'] = train_df.date_account_created.dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[['timestamp_first_active',\n",
    " 'gender',\n",
    " 'age',\n",
    " 'signup_method',\n",
    " 'signup_flow',\n",
    " 'language',\n",
    " 'affiliate_channel',\n",
    " 'affiliate_provider',\n",
    " 'signup_app',\n",
    " 'first_device_type',\n",
    " 'first_browser',\n",
    " 'account_year',\n",
    " 'account_month',\n",
    " 'account_day','country_destination']]\n",
    "\n",
    "test_df = test_df[['timestamp_first_active',\n",
    " 'gender',\n",
    " 'age',\n",
    " 'signup_method',\n",
    " 'signup_flow',\n",
    " 'language',\n",
    " 'affiliate_channel',\n",
    " 'affiliate_provider',\n",
    " 'signup_app',\n",
    " 'first_device_type',\n",
    " 'first_browser',\n",
    " 'account_year',\n",
    " 'account_month',\n",
    " 'account_day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [train_df,test_df]:\n",
    "    data.age = data.age.apply(lambda x: np.nan if x<18 else x)\n",
    "    data.age = data.age.apply(lambda x: np.nan if x>100 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace nan age values with mean age\n",
    "for data in [train_df,test_df]:\n",
    "    data.age.fillna(data.age.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for any nan values after pre-processing\n",
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, name=\"feature\"):\n",
    "    #Store the 25th and 75th percentile \n",
    "    q25,q75 = np.percentile(df[name],25), np.percentile(df[name],75)\n",
    "    #Calculate the Interquartile range\n",
    "    iqr_cut = 1.5*(q75-q25)\n",
    "    #Create variable of lower and upper cut\n",
    "    lower,upper = q25-iqr_cut, q75+iqr_cut\n",
    "    #Remove the outliers\n",
    "    df = df[(df[name] >= lower) & (df[name] <= upper)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df.copy()\n",
    "train = remove_outliers(train,'age')\n",
    "\n",
    "# Define inputs and target cols\n",
    "inputs_col = train.columns[:-1]\n",
    "target_col = ['country_destination']\n",
    "\n",
    "# Define inputs\n",
    "inputs = train[inputs_col].copy()\n",
    "target = train[target_col].copy()\n",
    "\n",
    "# Define numerical and categorical columns\n",
    "numerical_cols = inputs.select_dtypes(include=['int64','float64']).columns.to_list()\n",
    "categorical_cols = inputs.select_dtypes(include='object').columns.to_list()\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler().fit(inputs[numerical_cols])\n",
    "inputs[numerical_cols] = scaler.transform(inputs[numerical_cols])\n",
    "\n",
    "# label encoding\n",
    "for col in categorical_cols:\n",
    "    # label encoding\n",
    "    encoder = LabelEncoder().fit(inputs[col])\n",
    "    inputs[col] = encoder.transform(inputs[col])\n",
    "    \n",
    "enc_countries = {'NDF':0,'US':1,'FR':2,'CA':3,'GB':4,'ES':5,'IT':6,'PT':7,'NL':8,'DE':9,'AU':10,'other':11}\n",
    "target['country_destination'] = target['country_destination'].apply(lambda x:enc_countries[x])\n",
    "\n",
    "\n",
    "# Define X variable\n",
    "X = inputs[numerical_cols + categorical_cols]\n",
    "# Define y variable\n",
    "y = target['country_destination']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train:', len(X_train))\n",
    "print('y_train:', len(y_train))\n",
    "print('X_val:', len(X_test))\n",
    "print('y_train:', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(random_state=3, n_jobs=-1, max_depth=3, n_estimators=100, objective='multi:softprob', learning_rate=0.3, use_label_encoder=False)\n",
    "xgb.fit(X_train, y_train, eval_metric=\"merror\")\n",
    "train_accuracy_score = accuracy_score(xgb.predict(X_train), y_train)\n",
    "test_accuracy_score = accuracy_score(xgb.predict(X_test), y_test)\n",
    "train_ndcg_score = ndcg_score(pd.get_dummies(y_train).to_numpy(), xgb.predict_proba(X_train))\n",
    "test_ndcg_score = ndcg_score(pd.get_dummies(y_test).to_numpy(), xgb.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_score, test_accuracy_score, train_ndcg_score, test_ndcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_importance_df = pd.DataFrame({'features': X.columns,\n",
    "                  'importance': xgb.feature_importances_}).sort_values('importance',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(xgb_importance_df, x='importance', y='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "\n",
    "import pickle\n",
    "pkl_file = open(\"pkl_files/XGBoost_airbnb.pkl\", \"wb\")\n",
    "pickle.dump(xgb, pkl_file)\n",
    "pkl_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
